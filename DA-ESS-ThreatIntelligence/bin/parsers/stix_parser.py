import collections
import json
import logging
import lxml
from lxml import etree, objectify
import os
import re
import StringIO
import sys


from parsers import AbstractThreatIntelligenceParser
from parsers.parser_exceptions import ParserException, ParserEmptyException
from parsers.stix_schema import STIXParserSpecification
from parsers.utils import ParserUtils

import splunk
import splunk.rest
from splunk.clilib.bundle_paths import make_splunkhome_path
sys.path.append(make_splunkhome_path(["etc", "apps", "SA-ThreatIntelligence", "contrib"]))

import cybox
import ramrod
from stix.core import STIXPackage
from stix.utils import parser
import libtaxii.messages_11 as tm11


class STIXParser(STIXParserSpecification, AbstractThreatIntelligenceParser):
    
    def __init__(self, session_key):
        # Note: Method resolution order requires that the non-abstract mixin 
        # class, STIXParserSpecification, precede the abstract class in the declaration. 
        super(STIXParser, self).__init__()
        self._doc_type = 'stix'
        self._logger = logging.getLogger('threat_intelligence_manager')
        self.session_key = session_key

        # STIX documents use the filename as part of the document ID since multiple
        # documents can share the same ID. 
        self.use_filename = True
                
        # Cache for weight values assigned to input stanzas.
        self._weights = self.cache_weights()
        
        # Regex used for parsing filenames generated by TAXII feeds.
        self.taxii_stanza_rx = re.compile(r'^(\S+)_(?:TAXII)[^/]+$')
        
        # Populate stanza data (self._stanzas) and metadata (self._stanza_meta).
        # May raise REST exception.
        self._get_stanza_metadata(includes=['taxii'])
        
    def parse_stix_package(self, data):
        '''Parse an XML string representing a STIX package object.
        
        If the content cannot be parsed, attempt to update the content to the 
        current STIX version.

        Params:
            data - an XML string
            
        Returns:
            A STIXPackage object.
        '''
        
        try:
            return STIXPackage.from_xml(StringIO.StringIO(data))
        except (parser.UnknownVersionError, parser.UnsupportedVersionError, parser.UnsupportedRootElementError):
            try:
                # If we arrived here, we did not find a valid STIX version in this 
                # document, meaning it is likely a lower STIX version. Try to
                # up-convert to latest version of STIX.
                updated = ramrod.update(data)
                return STIXPackage.from_xml(updated.document.as_stringio())
            except (ramrod.errors.UpdateError, ramrod.errors.InvalidVersionError, ramrod.errors.UnknownVersionError):
                self._logger.exception('msg="UpdateError when parsing a STIX document" filename="%s"', self.filename)
        except lxml.etree.XMLSyntaxError:
            # Exceptions are not re-raised here because multiple STIXPackage
            # objects can result from a single TAXII PollResponse. 
            # Just log the error in this case as the likely case 
            # is that a single STIXPackage is in error, usually 
            # due to a missing CDATA tag. 
            self._logger.exception('msg="XMLSyntaxError when parsing a STIX document" filename="%s"', self.filename)
    
    def preprocess(self, filename, typ=None):
        '''Perform preliminary work prior to parsing: 
            - Read in the document.
            - Calculate document hash.
            
        Filename is stored and accessible to the parser object after preprocessing.
        
        Arguments:
            filename - The full path to a file.
            typ - The type of object, expected to be "Poll_Response" or "STIX_Package".
        
        Raises:
            IOError - Could not open file.
            ParserException - Invalid XML.
            Exception (other) - Any other error.
        '''
        
        # Reset initial state.
        self._clear()
        
        self.filename = os.path.abspath(filename)
        self._parsed_data = []

        with open(self.filename, 'r') as fh:

            # Read the file once to hash
            data = fh.read()
            hasher = self.hash_alg
            hasher.update(data)
            self.hash_value = hasher.hexdigest()
            
            failed = 0
            
            if typ == 'STIX_Package':
                # Single STIX document
                try:
                    package_data = self.parse_stix_package(data)
                    # Append a tuple consisting of (doc_id, package_data, threat_key)
                    self._parsed_data.append((package_data.id_, package_data, package_data.id_ + "|" + os.path.basename(self.filename)))
                except Exception:
                    failed += 1
                    self._logger.exception('msg="Unknown exception when parsing single STIXPackage" filename="%s"', self.filename)

                # Single document ID and threat key.
                self.doc_id = package_data.id_
                self.threat_key = self.doc_id + "|" + os.path.basename(self.filename)

            elif typ == 'Poll_Response':
                # Multiple STIX documents in a TAXII PollResponse
                poll_response = tm11.PollResponse.from_xml(data)

                # Single document ID and threat key associated with the polled collection.
                self.doc_id = poll_response.collection_name
                self.threat_key = self.doc_id + "|" + os.path.basename(self.filename)

                for num, data in enumerate(poll_response.content_blocks):
                    try:
                        package_data = self.parse_stix_package(data.content)
                        self._logger.debug('msg="STIXPackage found in PollResponse" filename="%s" document_number="%d" package_id="%s"', self.filename, num, package_data.id_)
                        # Append a tuple consisting of (doc_id, package_data, threat_key)
                        self._parsed_data.append((package_data.id_, package_data, package_data.id_ + "|" + os.path.basename(self.filename)))
                    except Exception:
                        failed += 1
                        self._logger.exception('msg="Unknown exception when parsing XML document in PollResponse" filename="%s" document_number="%d"', self.filename, num)

            else:
                raise ParserException('msg="Unknown document type" filename="%s"' % filename)

            self._logger.info('msg="Finished parsing STIX documents" filename="%s" success="%d" failed="%d"', self.filename, len(self._parsed_data), failed)

            # Set document to valid.
            self.is_valid = True

    def get_metadata(self):
        '''Construct a dictionary of metadata for the IOC currently being processed.'''
        return {'source_digest': self.hash_value,
                'source_path': self.filename,
                'source_processed_time': self.process_time,
                'source_status': None,  # TODO: what is this?
                'source_type': self.doc_type}
    
    def cache_weights(self):
        '''Cache the "weight" values associated with threat intelligence download input stanzas.'''

        weights = {}
        try:
            _, content = splunk.rest.simpleRequest('/services/data/inputs/threatlist',
                sessionKey=self.session_key,
                getargs={'output_mode': 'json',
                         'search': 'disabled="false"'})
            weights.update({i['name']: i['content']['weight'] for i in json.loads(content)['entry']})
        except (KeyError, ValueError, splunk.RESTException):
            self._logger.exception('Could not retrieve threatlist weights')

        return weights

    def stanza_updated(self, filename, last_run):
        '''Returns True if the metadata corresponding to the filename has been 
        updated since the last run, False otherwise.'''
        
        originating_stanza_match = self.taxii_stanza_rx.findall(os.path.basename(filename))
        
        if originating_stanza_match:
            return self._stanza_meta.get(originating_stanza_match[0]) > last_run
        return False
    
    def get_weight(self, filename):
        '''Get the weight associated with a specific input stanza definition. The
        format of the filename is used to associate between an input stanza
        and the actual file as there is no direct coupling here.
        
        Note: Right now only STIX documents generated from TAXII feed stanza 
        definitions are supported in this way.
        '''
        
        originating_stanza_match = self.taxii_stanza_rx.findall(os.path.basename(filename))
        
        if originating_stanza_match:
            return self._weights.get(originating_stanza_match[0])
        return None
    
    def get_attribution_data(self, doc_id, package_data, threat_key):
        '''Construct a dictionary representing threat attribution information.'''

        output = {'source_id': doc_id,
                  #'time': str(calendar.timegm(package_data.stix_header.get())
                  '_key': threat_key}

        # Get weight.
        weight = self.get_weight(self.filename)
        if weight:
            output['weight'] = weight

        # Use threat actor information if available.
        if package_data.threat_actors is not None:
            for ta in package_data.threat_actors:
                description = output.setdefault('description', [])
                threat_group = output.setdefault('threat_group', [])
                threat_category = output.setdefault('threat_category', [])
                if ta.short_description:
                    description.append(ta.short_description)
                threat_category.extend([str(i.value) for i in ta.types])
                if ta.title:
                    threat_group.append(ta.title)

        # Otherwise, try the STIX header
        if not output.get('description'):
            output['description'] = str(package_data.stix_header.description).strip()

        return output

    def has_observables(self, doc_id, package_data, threat_key):
        return (package_data.observables is not None and package_data.observables) or \
            (package_data.indicators is not None and package_data.indicators) or \
            (package_data.incidents is not None and package_data.incidents)
        
    def parse_observables(self, doc_id, package_data, threat_key):
        
        # Merged output for all collections.
        merged_observables = collections.defaultdict(list)
        
        to_process = []
        
        # Capture observables.
        if package_data.observables and package_data.observables is not None:
            to_process.extend([i.to_dict() for i in package_data.observables])

        # Capture indicators.
        if package_data.indicators and package_data.indicators is not None:
            to_process.extend([i.to_dict() for i in package_data.indicators.walk() if type(i) == cybox.core.observable.Observable])

        # Capture observables associated with incidents (cf. http://stixproject.github.io/documentation/idioms/related-observables/)
        if package_data.incidents and package_data.incidents is not None:
            to_process.extend([i.to_dict() for i in package_data.incidents.walk() if type(i) == cybox.core.observable.Observable])
        
        for obs in to_process:
            this_observable = collections.defaultdict(set)

            # Set "props" to a dictionary. If there are no observables, we will
            # bail out when we obtain the fieldmap.
            props = obs.get('object', {}).get('properties', {})
            if 'id' in obs:
                obs_id = obs['id']
            else:
                obs_idref = obs['idref'] if 'idref' in obs else ''
                self._logger.debug('status="Observable found with no ID" doc_id="%s" obs_idref="%s"', doc_id, obs_idref)
                continue
            
            # Detect wildcarding.
            if props.get('condition') == 'Contains':
                fmt = '*%s*'
            else:
                fmt = '%s'
                
            fieldmap = self._collection_spec.get(props.get('xsi:type'))
            if fieldmap:
                for input_field, output_field_list, target_collection, convert_function in fieldmap.fields.itervalues():
                    # We may need to extract some values from the nested dictionary
                    # via a full search path. These are represented in the spec
                    # as a period-separated list. This is basically equivalent to
                    # reduce(operator.getitem, l, i.to_dict()).
                    # If a list of values is encountered, we handle that.
                    raw_tmp_value = props
                    for input_field_path_component in input_field.split('.'):
                        if isinstance(raw_tmp_value, list):
                            raw_tmp_value = [inst.get(input_field_path_component, {}) for inst in raw_tmp_value]
                        elif isinstance(raw_tmp_value, dict):
                            raw_tmp_value = raw_tmp_value.get(input_field_path_component, '')
                        else:
                            pass

                    # handle items that are specified as {'value': ..., 'condition': ...} 
                    final_tmp_value = []
                    if isinstance(raw_tmp_value, list):
                        for inst in raw_tmp_value:
                            if isinstance(inst, dict):
                                # Order is important here.
                                if 'value' in inst and 'condition' in inst and inst.get('condition') == 'Contains':
                                    final_tmp_value.append(inst['value'])
                                    fmt = '*%s*'
                                elif 'value' in inst and 'condition' in inst and inst.get('condition') not in ['DoesNotEqual', 'DoesNotContain']:
                                    final_tmp_value.append(inst['value'])
                            else:
                                final_tmp_value.append(inst)
                    elif isinstance(raw_tmp_value, dict):
                        if 'value' in raw_tmp_value:
                            # Order is important here.
                            if 'condition' in raw_tmp_value and raw_tmp_value.get('condition') == 'Contains':
                                final_tmp_value.append(raw_tmp_value['value'])
                                fmt = '*%s*'
                            elif 'condition' in raw_tmp_value and raw_tmp_value.get('condition') not in ['DoesNotEqual', 'DoesNotContain']:
                                final_tmp_value.append(raw_tmp_value['value'])
                            elif 'condition' not in raw_tmp_value:
                                final_tmp_value.append(raw_tmp_value['value'])
                            else:
                                # Value skipped
                                pass
                        else:
                            # Something went wrong here - we should not have a dict
                            # at this stage that doesn't contain a "value" key.
                            self._logger.error('status="Invalid path for retrieving field value from observable." doc_id="%s" obs_id="%s", input_field="%s"', doc_id, obs_id, input_field)
                    else:
                        final_tmp_value.append(raw_tmp_value)
                        
                    if final_tmp_value:
                        # Assume the first field name in the output field list 
                        # is the default output field name. If it is not, the 
                        # convert_function() call is expected to override it.
                        for field_name, field_value in convert_function(output_field_list[0], final_tmp_value):
                            # Explicit check for None and empty string is intentional. 
                            if field_name in output_field_list and field_value is not None and field_value != "":
                                this_observable[field_name].add(fmt % field_value)

                if this_observable.keys():
                    # Add the key fields.
                    this_observable['_key'] = doc_id + ':' + obs_id
                    this_observable['threat_key'] = threat_key
                
                    # Add to the output.
                    merged_observables[target_collection].append(ParserUtils.make_json_serializable(this_observable))

                else:
                    self._logger.debug('status="No fields could be retrieved from observable." doc_id="%s" obs_id="%s"', doc_id, obs_id)

        return merged_observables

    def parse(self, limits):
        '''Parse a STIX Package and populate KV store collections.
        
        Arguments:
            ioc - An lxml.objectify tree representing an IOC document.
        
        Returns:
            A tuple ({metadata_field: value}, {target_collection: {intel_dict})
            
        '''

        if len(self._parsed_data) > 0:
            for stix_package in self._parsed_data:
                
                doc_id, package_data, threat_key = stix_package

                # Retrieve metadata.
                metadata = self.get_metadata()
                document_attribution = self.get_attribution_data(doc_id, package_data, threat_key)
                metadata.update(document_attribution)
        
                if self.has_observables(doc_id, package_data, threat_key):
                    
                    # For debugging only.
                    #self._logger.info('METADATA: %s', metadata)
                    #self._logger.info('OUTPUT: %s', intel)
        
                    intel = self.parse_observables(doc_id, package_data, threat_key)
                    # Return the metadata and output.
                    # Note the use of "yield" so this can be consumed as a generator.
                    if intel:
                        yield metadata, intel
                    else:
                        self._logger.debug('status="No threat intelligence retrieved from document" filename="%s" document_id="%s"', self.filename, doc_id)
                        yield None, None
                else:
                    self._logger.debug('status="No observables found in document" filename="%s" document_id="%s"', self.filename, doc_id)
                    yield None, None
        else:
            raise ParserEmptyException()
